\chapter{Introduction}
Digital representations of three-dimensional objects are of great importance to many applications. Often the 3D models are hand-build which can be a tedious and time consuming task thus making automatic modelling desirable. In robotics, models of the environment are used as a priori knowledge for collision checking and thus relying only on hand-build models limits the application of robots to known environments containing known objects. \\

One method for recording 3D models is to mount a stereo camera on the end effector of a robot arm (eye-in-hand) and let the robot move the camera to the views needed to generate the model. This way the robot is able to assess unknown objects and update the work cell model accordingly. The precision of the model is not only dependent on the quality of robot arm and camera, but also on the calibration of the system. The camera can be calibrated using a marker plate in different poses thus calculating intrinsic and extrinsic parameters for the camera \cite{Zhang2000}. The system can be further calibrated in a process called hand-eye calibration solving for the unknown spatial relationships in the kinematic chain.\\

%Another important part of 3D modelling is the reconstruction problem, reasoning about either surface, volume or both. Depending on the application there are very different demands for the final model. If it is used for collision detection a coarse model is more efficient, while a model for grasping needs to be sufficiently detailed to infer grasping points. Modelling is a multi-step process where the gathered data is first transformed, filtered and combined to form a point cloud representing the object. Next an indicator function is approximated to best fit the normals of the inferred solid. Finally a mesh is generated from the indicator function. Using wavelets to approximate the indicator function provides a localised, multi-resolution representation and thus addresses the trade-off between faster coarse models and slower fine models.\\

Normally the hand-eye calibration is performed based on images capturing a marker plate from different angles. Features matched between the images are then used to formulate a set of equations to solve for the unknown transforms from end-effector to camera and from robot base to the object. In this work, another approach is suggested, performing the calibration based on point clouds obtained from capturing the object. There are several advantages of this, but most importantly the process can be fully integrated in the robots behaviour, since it does not require a special calibration marker and the system can be calibrated locally, thus potentially increasing the accuracy.\\

\textit{It is hypothesised that a locally calibrated system can generate significantly better models than the same system without calibration and that basing the entire system on the ROS framework will reduce development time.} \\

Each component will be evaluated isolated and the calibration will be evaluated in a manipulative study, where a known object is modelled before and after calibrating the system. Calibration will be further evaluated in comparison to the hand-eye calibration system implemented in ROS. The produced point clouds are visually as well as quantitatively compared to the true 3D model of the object. The novelties in this report are hand-eye calibration based on point cloud data and implementing the entire system in Robot Operating System(ROS).\\

In chapter 2 the system is analysed on component level to formulate a requirements specification forming the basis for chapter 3 describing decision making, chapter 4 describing robotics, chapter 5 describing computer vision and chapter 6 describing 3D modelling. Chapter 7 presents the proposed point cloud based calibration system and finally in chapter 8 to 10 the evaluation method and findings are presented and discussed, leading to a conclusion.